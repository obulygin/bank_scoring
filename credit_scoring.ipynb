{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "pd.options.display.max_colwidth = 500\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJOBS = 6\n",
    "RANDOM = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зарузим датафрейм и изучим его поподробнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"crx.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      "0     690 non-null object\n",
      "1     690 non-null object\n",
      "2     690 non-null float64\n",
      "3     690 non-null object\n",
      "4     690 non-null object\n",
      "5     690 non-null object\n",
      "6     690 non-null object\n",
      "7     690 non-null float64\n",
      "8     690 non-null object\n",
      "9     690 non-null object\n",
      "10    690 non-null int64\n",
      "11    690 non-null object\n",
      "12    690 non-null object\n",
      "13    690 non-null object\n",
      "14    690 non-null int64\n",
      "15    690 non-null object\n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-    383\n",
       "+    307\n",
       "Name: 15, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[15].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Видим, что в датасете есть числовые (**int64**, **float64**) и нечисловые признаки (**object**). Первые 14 столбцов – признаки, а 15 содержит целевую переменную, которую мы и будет прогнозировать (одобрена или нет кредитная карта для конкретного клиента). В исходных данных 307 заявок было одобрено, 383 – отклонено.  \n",
    "Если внимательнее изучить данные, то можно обнаружить, что в них присутствуют значения, которые представлены, как \"**?**\". Судя по всему, это пропуски в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     12\n",
       "1     12\n",
       "2      0\n",
       "3      6\n",
       "4      6\n",
       "5      9\n",
       "6      9\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13    13\n",
       "14     0\n",
       "15     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isin(['?']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"**?**\" присутствуют в столбцах, как с числовыми (1), так и нечисловыми признаками (0, 3-6, 13). От пропусков в данных необходимо избавиться, т.к. они могут сильно влиять на точность моделей. Для начала заменим все \"**?**\" на **NaN** при помощи метода **replace**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = df[1].astype('float64') \n",
    "df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     12\n",
       "1     12\n",
       "2      0\n",
       "3      6\n",
       "4      6\n",
       "5      9\n",
       "6      9\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13    13\n",
       "14     0\n",
       "15     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим pipeline с предобработкой данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = df.iloc[:,0:15] , df.iloc[:,15]\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "cat_columns = X.dtypes[X.dtypes == 'object'].index\n",
    "num_columns = X.dtypes[X.dtypes != 'object'].index\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('mms', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "transformer = ColumnTransformer(transformers=\n",
    "                                [('num', num_pipe, num_columns),\n",
    "                                 ('cat', cat_pipe, cat_columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим нашу выборку на тестовую (на которой будем обучать модели) и тренировочную (на которой будем проверять результаты) при помощи функции **train_test_split** в соотношении 70/30 и зафиксируем **seed** для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "res = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'logisticregression__solver': 'newton-cg', 'logisticregression__class_weight': None, 'logisticregression__C': 48.32930238571752}\n",
      "F-мера на перекрестной проверке: 0.8809905513773048\n",
      "F-мера логистической регрессии на тестовом наборе: 0.8765957446808511\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe = make_pipeline(transformer, LogisticRegression(random_state=RANDOM, n_jobs=NJOBS))\n",
    "logreg_params_grid = {'logisticregression__C': np.logspace(-4, 2, 20), \n",
    "                      'logisticregression__solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                      'logisticregression__class_weight': ['balanced', None]\n",
    "                     }\n",
    "logreg_grid = RandomizedSearchCV(logreg_pipe, logreg_params_grid, scoring='f1', random_state=RANDOM) \n",
    "logreg_grid.fit(X_train, y_train)\n",
    "print('Лучшие параметры:', logreg_grid.best_params_)\n",
    "print('F-мера на перекрестной проверке:', logreg_grid.best_score_)\n",
    "print('F-мера логистической регрессии на тестовом наборе:', logreg_grid.score(X_test, y_test))\n",
    "res['LogReg'] = logreg_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'decisiontreeclassifier__min_samples_split': 87, 'decisiontreeclassifier__max_features': None, 'decisiontreeclassifier__max_depth': 11, 'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__class_weight': None}\n",
      "F-мера на перекрестной проверке: 0.853534582310326\n",
      "F-мера дерева решений на тестовом наборе: 0.8514056224899599\n"
     ]
    }
   ],
   "source": [
    "dtc_pipe = make_pipeline(transformer, DecisionTreeClassifier(random_state=RANDOM))\n",
    "dtc_params_grid = {'decisiontreeclassifier__min_samples_split': range(2, 200, 5), \n",
    "                  'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "                   'decisiontreeclassifier__max_depth': range(1, 35),\n",
    "                  'decisiontreeclassifier__class_weight': ['balanced', None],\n",
    "                  'decisiontreeclassifier__max_features': ['auto', None, 'log2']}\n",
    "dtc_grid = RandomizedSearchCV(dtc_pipe, dtc_params_grid, scoring='f1', random_state=RANDOM)  \n",
    "dtc_grid.fit(X_train, y_train)\n",
    "print('Лучшие параметры:', dtc_grid.best_params_)\n",
    "print('F-мера на перекрестной проверке:', dtc_grid.best_score_)\n",
    "print('F-мера дерева решений на тестовом наборе:', dtc_grid.score(X_test, y_test))\n",
    "res['DTC'] = dtc_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'randomforestclassifier__n_estimators': 75, 'randomforestclassifier__min_samples_split': 32, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__max_depth': 22, 'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__class_weight': None}\n",
      "F-мера на перекрестной проверке: 0.8905675084259512\n",
      "F-мера случайного леса на тестовом наборе: 0.8934426229508197\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe = make_pipeline(transformer, RandomForestClassifier(random_state=RANDOM, n_jobs=NJOBS))\n",
    "rfc_params_grid = {'randomforestclassifier__min_samples_split': range(2, 100, 5), \n",
    "                   'randomforestclassifier__n_estimators': range(50, 200, 5), \n",
    "                   'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "                    'randomforestclassifier__max_depth': range(1, 35),\n",
    "                   'randomforestclassifier__class_weight': ['balanced', None],\n",
    "                   'randomforestclassifier__max_features': ['auto', None, 'log2']}\n",
    "rfc_grid = RandomizedSearchCV(rfc_pipe, rfc_params_grid, scoring='f1', random_state=RANDOM)  \n",
    "rfc_grid.fit(X_train, y_train)\n",
    "print('Лучшие параметры:', rfc_grid.best_params_)\n",
    "print('F-мера на перекрестной проверке:', rfc_grid.best_score_)\n",
    "print('F-мера случайного леса на тестовом наборе:', rfc_grid.score(X_test, y_test))\n",
    "res['RFC'] = rfc_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__class_weight': None, 'svc__C': 0.06951927961775606}\n",
      "F-мера на перекрестной проверке: 0.887491855673543\n",
      "F-мера метода опорных векторов на тестовом наборе: 0.8813559322033899\n"
     ]
    }
   ],
   "source": [
    "svc_pipe = make_pipeline(transformer, svm.SVC(random_state=RANDOM))\n",
    "svc_params_grid = {'svc__C': np.logspace(-4, 2, 20), \n",
    "                   'svc__gamma': ['scale', 'auto'],\n",
    "                   'svc__class_weight': ['balanced', None],\n",
    "                   'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "svc_grid = RandomizedSearchCV(svc_pipe, svc_params_grid, scoring='f1', random_state=RANDOM)  \n",
    "svc_grid.fit(X_train, y_train)\n",
    "print('Лучшие параметры:', svc_grid.best_params_)\n",
    "print('F-мера на перекрестной проверке:', svc_grid.best_score_)\n",
    "print('F-мера метода опорных векторов на тестовом наборе:', svc_grid.score(X_test, y_test))\n",
    "res['SVC'] = svc_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogReg': 0.8765957446808511,\n",
       " 'DTC': 0.8514056224899599,\n",
       " 'RFC': 0.8934426229508197,\n",
       " 'SVC': 0.8813559322033899}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на матрицу ошибок лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75,  13],\n",
       "       [ 16, 103]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = logreg_grid.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda98ee28fd21e54513b617f25a4bc88d8a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
